{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model form\n",
    "\n",
    "This notebook introduces the model form, its connections to tensor methods, and equivalent parameterizations shown in the paper.\n",
    "\n",
    "At the end, we construct each experts' weights explicitly, showing the absence of structural low-rankness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "\n",
    "input_dim = 16\n",
    "output_dim = 64\n",
    "n_experts = 32\n",
    "\n",
    "C = torch.randn(n_experts, output_dim)\n",
    "W = torch.randn(input_dim, output_dim)\n",
    "\n",
    "D = torch.randn(input_dim, output_dim)\n",
    "\n",
    "# dummy gating parameter -- any linear transformation\n",
    "G = torch.randn(input_dim, n_experts)\n",
    "E = torch.randn(input_dim, input_dim) # dummy encoder\n",
    "\n",
    "x = torch.randn(input_dim) # pre-MLP token representation\n",
    "z = torch.nn.functional.gelu(E.T@x) # hidden units, with whatever activation function\n",
    "a = torch.nn.functional.softmax(G.T@z, dim=0) # generate the conditional units (or 'expert coefficients') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hadamard-factorization\n",
    "\n",
    "Our weight tensor $\\boldsymbol{\\mathcal{W}}\\in\\mathbb{R}^{N\\times H \\times O}$ is defined elementwise as\n",
    "\n",
    "$\n",
    "    \\boldsymbol{\\mathcal{W}}(n,h,:) = \\mathbf{c}_n * \\mathbf{d}_h \\in \\mathbb{R}^{O},\n",
    "      \\quad \\forall\\,n\\!\\in\\{1,\\ldots,N\\},\\; h\\!\\in\\{1,\\ldots,H\\}\n",
    "$\n",
    "\n",
    "Constructing the tensor explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros(n_experts, input_dim, output_dim)\n",
    "\n",
    "for n in range(n_experts):\n",
    "    for h in range(input_dim):\n",
    "        W[n, h] = C[n] * D[h] # note: all O-dimensional vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**, as per Appendix *Sect. A.3.1*, we can also understand this parameterization through the khatri-rao product:\n",
    "\n",
    "$\n",
    "\\mathbf{W}_{(3)} := \\left(\\mathbf{C} \\odot \\mathbf{D}\\right)^\\top\\in\\mathbb{R}^{O\\times(N\\cdot H)}.\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khatri-Rao parameterization is equivalent\n"
     ]
    }
   ],
   "source": [
    "import tensorly as tl\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "W_kr_unfolded = tl.tenalg.khatri_rao([C, D]).T # parameterize the mode-3 unfolding\n",
    "W_kr = tl.fold(W_kr_unfolded, mode=2, shape=W.shape) # and re-shape\n",
    "\n",
    "assert torch.allclose(W, W_kr, atol=1e-6)\n",
    "print(\"Khatri-Rao parameterization is equivalent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full MxD forward pass is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mod = torch.zeros(output_dim)\n",
    "for n in range(n_experts):\n",
    "    # linear combination of N experts' outputs\n",
    "    y_mod += a[n] * W[n].T @ z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the equivalent forward pass from Lemma 2:\n",
    "\n",
    "$\n",
    "\\mathbf{y} = (\\mathbf{C}^\\top\\mathbf{a})\n",
    "*\n",
    "(\\mathbf{D}^\\top\\mathbf{z})\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementwise equals explicit MoE!\n"
     ]
    }
   ],
   "source": [
    "y = (C.T@a) * (D.T@z)\n",
    "\n",
    "assert torch.allclose(y, y_mod)\n",
    "print('Elementwise equals explicit MoE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, as a series of two tensor contractions (following the tensorized interpretation in *Sect. A.3.2* of the Appendix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementwise equals mode-n product forward pass!\n"
     ]
    }
   ],
   "source": [
    "import tensorly as tl\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "y_moden = tl.tenalg.multi_mode_dot(W, [a, z], modes=[0, 1])\n",
    "\n",
    "assert torch.allclose(y, y_moden)\n",
    "print('Elementwise equals mode-n product forward pass!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full-rankness\n",
    "\n",
    "We can also verify the (normalized) rank of each expert is close to 1 when randomly initialized (i.e., there are no structural rank constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementwise equals explicit MoE!\n"
     ]
    }
   ],
   "source": [
    "y_rank = torch.zeros(output_dim)\n",
    "\n",
    "ranks = []\n",
    "for n in range(n_experts):\n",
    "    Wn = D@torch.diag(C[n]) # materialize the nth expert\n",
    "    \n",
    "    ranks += [torch.linalg.matrix_rank(Wn)]\n",
    "\n",
    "    # compute the output again to assert correctness\n",
    "    y_rank += a[n] * Wn.T @ z\n",
    "\n",
    "assert torch.allclose(y_rank, y_mod)\n",
    "print('Elementwise equals explicit MoE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (normalized) rank of experts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mean (normalized) rank of experts:')\n",
    "torch.mean(torch.stack(\n",
    "    [rank / min(input_dim, output_dim) for rank in ranks]\n",
    ")).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
